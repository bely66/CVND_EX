{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bely66/CV_EX/blob/master/BN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8HnPfJH4OCD",
        "colab_type": "text"
      },
      "source": [
        "# Batch Normalization (BN)\n",
        "\n",
        "**Paper** [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf) \n",
        "\n",
        "**Introduction**  \n",
        "Batch normalization can be interpreted as conducting preprocessing at every layer of the network, where it is integrated into the network via a simple differentiable way.\n",
        "Batch Normalization,  is one of the most important techniques for deep learning, developed by Ioffe and Szegedy, that makes the neural network much robust to the choice of hyper parameters, by enforcing the activations of  a layer to take a Gaussian distribution. \n",
        "When training even a simple model, normalizing (or standardizing) the input data (or features) can  speed up the training  process, where standardizing transforms data to have a mean of zero and a standard deviation of 1. Intuitively, without normalization of the input features, the cost function could be elongated in one direction than the other, making it difficult for optimization to find a minima (requires more steps and smaller learning rate.) \n",
        "\n",
        "\n",
        "**Why BN works**  \n",
        "Covariate Shift: \"When the input distribution to a learning system changes, it is said to experience covariate shift (Shimodaira, 2000). This is typically handled via domain adaptation (Jiang, 2008). However, the notion of covariate shift can be extended beyond the learning system as a whole, to apply to its parts, such as a sub-network or a layer\"\n",
        "Internal Covariate Shift: BN draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. \n",
        "BN allows each layer of network to learn a little bit more independently of other layers, which speeds the learning.\n",
        "\n",
        "\n",
        "By: [Ibrahim Sobh](https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsyRyt2Y9Abk",
        "colab_type": "text"
      },
      "source": [
        "## Basic Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqMUGo04Tbx",
        "colab_type": "code",
        "outputId": "1d7f7ec9-ae42-488f-90a5-c4e78685216f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "import pickle\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot as plt\n",
        "seed(13)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YgH5WyU4UMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAet_HCu4hVa",
        "colab_type": "code",
        "outputId": "28d4164c-64a6-451c-c4f8-56174f650a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "# Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG2RN7Hd6Ar5",
        "colab_type": "text"
      },
      "source": [
        "## Without Batch Normalization (BN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9LvL-sQ4vDd",
        "colab_type": "code",
        "outputId": "3aea9d2e-b8a8-4f62-f520-407df961216f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Model \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd5myu-x4M8E",
        "colab_type": "code",
        "outputId": "091e81fa-2cad-4254-b40b-f21024ffaf61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train\n",
        "history1 = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 1.8346 - acc: 0.3284 - val_loss: 1.5850 - val_acc: 0.4279\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 10s 190us/step - loss: 1.4887 - acc: 0.4565 - val_loss: 1.3262 - val_acc: 0.5287\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 1.3478 - acc: 0.5172 - val_loss: 1.3150 - val_acc: 0.5327\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 1.2537 - acc: 0.5555 - val_loss: 1.1517 - val_acc: 0.5909\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 1.1748 - acc: 0.5843 - val_loss: 1.0603 - val_acc: 0.6263\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 1.1039 - acc: 0.6114 - val_loss: 1.0419 - val_acc: 0.6364\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 10s 190us/step - loss: 1.0407 - acc: 0.6347 - val_loss: 0.9634 - val_acc: 0.6618\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 10s 192us/step - loss: 0.9907 - acc: 0.6525 - val_loss: 0.9223 - val_acc: 0.6776\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.9502 - acc: 0.6666 - val_loss: 0.9248 - val_acc: 0.6779\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.9132 - acc: 0.6798 - val_loss: 0.8933 - val_acc: 0.6906\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 10s 190us/step - loss: 0.8827 - acc: 0.6914 - val_loss: 0.8417 - val_acc: 0.7081\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.8552 - acc: 0.7018 - val_loss: 0.8113 - val_acc: 0.7202\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.8312 - acc: 0.7106 - val_loss: 0.7985 - val_acc: 0.7266\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.8082 - acc: 0.7180 - val_loss: 0.7819 - val_acc: 0.7260\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.7889 - acc: 0.7258 - val_loss: 0.7523 - val_acc: 0.7428\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.7707 - acc: 0.7332 - val_loss: 0.7495 - val_acc: 0.7415\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.7625 - acc: 0.7342 - val_loss: 0.7346 - val_acc: 0.7468\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.7466 - acc: 0.7422 - val_loss: 0.7170 - val_acc: 0.7523\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 0.7394 - acc: 0.7441 - val_loss: 0.7418 - val_acc: 0.7444\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.7312 - acc: 0.7486 - val_loss: 0.7108 - val_acc: 0.7557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87HlrT2q6kpg",
        "colab_type": "text"
      },
      "source": [
        "## Without Batch Normalization (BN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eDAMkH16o3R",
        "colab_type": "code",
        "outputId": "45c25674-a3a7-49e9-d8aa-20f8e0ff4d02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "model_bn = Sequential()\n",
        "model_bn.add(Conv2D(32, (3, 3), padding='same', use_bias=False,\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Activation('relu'))\n",
        "\n",
        "model_bn.add(Conv2D(32, (3, 3), use_bias=False))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model_bn.add(Conv2D(64, (3, 3), use_bias=False, padding='same'))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(Conv2D(64, (3, 3), use_bias=False))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Activation('relu'))\n",
        "model_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model_bn.add(Flatten())\n",
        "model_bn.add(Dense(512, use_bias=False))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Activation('relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model_bn.add(Dense(num_classes, use_bias=False))\n",
        "model_bn.add(BatchNormalization())\n",
        "model_bn.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
        "\n",
        "model_bn.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_bn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 32)        864       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 30, 30, 32)        9216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 15, 15, 64)        18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 13, 13, 64)        36864     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               1179648   \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                5120      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,253,000\n",
            "Trainable params: 1,251,572\n",
            "Non-trainable params: 1,428\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-KiTtlE7Lro",
        "colab_type": "code",
        "outputId": "462ac363-de50-44c7-e213-7129b9e83ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Train\n",
        "history2 = model_bn.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 16s 329us/step - loss: 1.1857 - acc: 0.6027 - val_loss: 1.1213 - val_acc: 0.6182\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 15s 308us/step - loss: 0.8198 - acc: 0.7284 - val_loss: 0.9249 - val_acc: 0.6769\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.6595 - acc: 0.7815 - val_loss: 0.8612 - val_acc: 0.7097\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.5469 - acc: 0.8193 - val_loss: 0.7630 - val_acc: 0.7477\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.4505 - acc: 0.8508 - val_loss: 0.7530 - val_acc: 0.7418\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.3608 - acc: 0.8835 - val_loss: 0.6652 - val_acc: 0.7835\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2972 - acc: 0.9059 - val_loss: 0.7531 - val_acc: 0.7697\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 0.2416 - acc: 0.9249 - val_loss: 0.7081 - val_acc: 0.7830\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1979 - acc: 0.9393 - val_loss: 0.8003 - val_acc: 0.7560\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 15s 308us/step - loss: 0.1702 - acc: 0.9478 - val_loss: 0.7064 - val_acc: 0.7854\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1453 - acc: 0.9578 - val_loss: 0.7650 - val_acc: 0.7744\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1257 - acc: 0.9632 - val_loss: 0.7473 - val_acc: 0.7820\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.1154 - acc: 0.9661 - val_loss: 0.7517 - val_acc: 0.7819\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.1014 - acc: 0.9705 - val_loss: 0.8437 - val_acc: 0.7682\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.0944 - acc: 0.9722 - val_loss: 0.7797 - val_acc: 0.7843\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.0856 - acc: 0.9750 - val_loss: 0.8219 - val_acc: 0.7839\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.0789 - acc: 0.9761 - val_loss: 0.8143 - val_acc: 0.7849\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.0718 - acc: 0.9789 - val_loss: 0.8768 - val_acc: 0.7694\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.0662 - acc: 0.9806 - val_loss: 0.8744 - val_acc: 0.7764\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.0639 - acc: 0.9813 - val_loss: 0.8711 - val_acc: 0.7809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEnoUn4R7WEH",
        "colab_type": "text"
      },
      "source": [
        "## Compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ksMyY37YGo",
        "colab_type": "code",
        "outputId": "d657350d-521c-4ff1-be36-2838f26bfa25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(history1.history['val_acc'])\n",
        "plt.plot(history2.history['val_acc'])\n",
        "plt.title('model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['without BN', 'with BN'], loc='lower right')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd2cb5e0240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBPQ/wPH16CDLns5MgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}